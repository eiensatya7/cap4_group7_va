{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download VDO from youtube¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pafy, youtube-dl and moviepy packages to be installe\n",
    "#pip install pafy \n",
    "#pip installyoutube-dl \n",
    "#pip install moviepy\n",
    "\n",
    "#Pafy is a Python library for interacting with YouTube from within your Python programs. It has many features.\n",
    "\n",
    "#Pafy is optionally depends on youtube-dl so therefore for more stable usage it is recommended to install youtube-dl before installing pafy. Below is the command to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pafy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install youtube-dl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pafy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'C:/CAP4/HumanActivityRecognition/YoutubeVDOfile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_videos(youtube_video_url, output_directory):\n",
    "    # Creating a Video object which includes useful information regarding the youtube video.\n",
    "    video = pafy.new(youtube_video_url)\n",
    "\n",
    "    # Getting the best available quality object for the youtube video.\n",
    "    video_best = video.getbest()\n",
    "\n",
    "    # Constructing the Output File Path\n",
    "    output_file_path = f'{output_directory}/{video.title}.mp4'\n",
    "\n",
    "    # Downloading the youtube video at the best available quality.\n",
    "    video_best.download(filepath = output_file_path, quiet = True)\n",
    "\n",
    "    # Returning Video Title\n",
    "    return video.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading The YouTube Video\n",
    "#video_title = download_youtube_videos('www.youtube.com/watch?v=JVzf9rtgf9Y&list=RDCMUCJbg_yirB5vm9VKn5yLGCKw&index=4', output_directory)\n",
    "\n",
    "#print(video_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the YouTube Video's path you just downloaded\n",
    "#input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "#print(input_video_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play VDO in Jupyter NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/CAP4/HumanActivityRecognition/YoutubeVDOfile/Flip Book Compilation by Pro Animators.mp4\n"
     ]
    }
   ],
   "source": [
    "# Data read - All Required data for VideoObjectDetection are in datafolder\n",
    "dataFolder = \"C:/CAP4/HumanActivityRecognition/YoutubeVDOfile/\"\n",
    "VDO_Input =\"Flip Book Compilation by Pro Animators.mp4\"\n",
    "input_file_path=os.path.join(dataFolder, VDO_Input)\n",
    "print(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video.from_file(input_file_path, width=320, height=320)\n",
    "#Video.from_file(input_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Jupyter widget could not be displayed because the widget state could not be found. This could happen if the kernel storing the widget is no longer available, or if the widget state was not saved in the notebook. You may be able to create the widget by running the appropriate cells.\n",
    "Different image on each page of the book, and as we flip these pages, we get the animation . This is even call it a kind of video. The visualization gets better the faster we flip the pages. In other words, this visual is a collection of different images arranged in a particular order.\n",
    "\n",
    "Similarly, videos are nothing but a collection of a set of images. These images are called frames and can be combined to get the original video. So, a problem related to video data is not that different from an image classification or an object detection problem. There is just one extra step of extracting frames from the video.\n",
    "\n",
    "Frame rate, then, is the speed at which those images are shown, or how fast you “flip” through the book. It’s usually expressed as “frames per second,” or FPS. So if a video is captured and played back at 24fps, that means each second of video shows 24 distinct still images.\n",
    "Frame rate greatly impacts the style and viewing experience of a video. Different frame rates yield different viewing experiences.Movies are usually displayed at 24fps, since this frame rate is similar to how we see the world and creates a very cinematic look¶\n",
    "Different frame rates yield different results, so selecting the best one means going with the option that best fits what we’re trying to create. So there is no such thing as the “best” frame rate\n",
    "24fps – this is the minimum speed needed to capture video while still maintaining realistic motion\n",
    "Estimate of video frame count and duration - There are many ways - cv2 is popular\n",
    "OpenCV is a cross-platform library using which we can develop real-time computer vision applications. It mainly focuses on image processing, video capture and analysis including features like face detection and object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport cv2\\n\\ncap = cv2.VideoCapture(input_file_path)\\nfps = cap.get(cv2.CAP_PROP_FPS)      # OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\\nframe_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\\n\\n## Count the total numbers of frames and frames per second of a given video by providing  cv2.CAP_PROP_FRAME_COUNT \\n## and cv2.CAP_PROP_FPS to get() method.\\n## Calculate the duration of the video in seconds by dividing frames and fps.\\n\\nduration = frame_count/fps\\n\\nprint(\\'fps = \\' + str(fps))\\nprint(\\'number of frames = \\' + str(frame_count))\\nprint(\\'duration (S) = \\' + str(duration))\\n\\nminutes = int(duration/60)\\nseconds = duration%60\\nprint(\\'duration (M:S) = \\' + str(minutes) + \\':\\' + str(seconds))  ## In Minute and seconds\\n\\ncap.release()\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(input_file_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)      # OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "## Count the total numbers of frames and frames per second of a given video by providing  cv2.CAP_PROP_FRAME_COUNT \n",
    "## and cv2.CAP_PROP_FPS to get() method.\n",
    "## Calculate the duration of the video in seconds by dividing frames and fps.\n",
    "\n",
    "duration = frame_count/fps\n",
    "\n",
    "print('fps = ' + str(fps))\n",
    "print('number of frames = ' + str(frame_count))\n",
    "print('duration (S) = ' + str(duration))\n",
    "\n",
    "minutes = int(duration/60)\n",
    "seconds = duration%60\n",
    "print('duration (M:S) = ' + str(minutes) + ':' + str(seconds))  ## In Minute and seconds\n",
    "\n",
    "cap.release()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total number of frames in a video file¶\n",
    "cap.get(cv2.CAP_PROP_FRAME_COUNT), which reads the head information of this video file, which may can not reflect the real frame count of video. There are some wrong frames in this vidoe, which cause us to compute wrong video duration.\n",
    "Use loop frmae by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "import os, os.path\n",
    "import cv2\n",
    "#import csv\n",
    "#import pandas as pd\n",
    "import numpy  as np\n",
    "#import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp  #For Audio\n",
    "\n",
    "#pip install pydub\n",
    "from pydub import AudioSegment # For Audio extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/CAP4/HumanActivityRecognition/YoutubeVDOfile/\\VDOFrames\n"
     ]
    }
   ],
   "source": [
    "# Set root_folder where all inputs VDO are kept\n",
    "#AStepARootFolder = Drive+\"\\\\GG-12-6\\\\AD-VDO\\\\InVDOs\"\n",
    "root_folder = \"C:/CAP4/HumanActivityRecognition/YoutubeVDOfile/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FramesVdo  = root_folder+\"\\\\VDOFrames\"\n",
    "FullAudio  = root_folder+\"\\FullAudio\"\n",
    "\n",
    "print(FramesVdo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio = root_folder+\"/Audio\"\n",
    "\n",
    "if not os.path.exists(FramesVdo):\n",
    "   os.makedirs(FramesVdo) \n",
    "\n",
    "#if not os.path.exists(audio):\n",
    "#   os.makedirs(audio) \n",
    "   \n",
    "if not os.path.exists(FullAudio):\n",
    "   os.makedirs(FullAudio)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullAudio\n",
      "C:/CAP4/HumanActivityRecognition/YoutubeVDOfile/FullAudio\n",
      "VDOFrames\n",
      "C:/CAP4/HumanActivityRecognition/YoutubeVDOfile/VDOFrames\n"
     ]
    }
   ],
   "source": [
    "for child in os.listdir(root_folder):\n",
    "   \n",
    "    baseimagefolders = os.path.join(root_folder, child)\n",
    "    print(child)\n",
    "    print(baseimagefolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(baseimagefolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract VDO frames and Full Audio\n",
    "\n",
    "file = \"Flip Book Compilation by Pro Animators.mp4\"\n",
    "suffix = '.jpg'   \n",
    "#1. \n",
    "extension = os.path.splitext(file)[1]  ### - Extension - (output= .mp4)\n",
    "#2. \n",
    "FineName = os.path.splitext(file)[0]  ####- Fine Name without extension - (output= VDO-AD-200) \n",
    "#3. \n",
    "newfilename = os.path.basename(FineName)+suffix  ###- (output= abc.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".mp4\n",
      "Flip Book Compilation by Pro Animators\n",
      "Flip Book Compilation by Pro Animators.jpg\n"
     ]
    }
   ],
   "source": [
    "print(extension)\n",
    "print(FineName)\n",
    "print(newfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = True\n",
    "count = 0\n",
    "\n",
    "root_folder = \"C:/CAP4/HumanActivityRecognition/YoutubeVDOfile\"\n",
    "vdofile = \"C:/CAP4/HumanActivityRecognition/YoutubeVDOfile/Flip Book Compilation by Pro Animators.mp4\"\n",
    "#root_folder = \"E:\\\\0-CapstoneProject\\\\1-Next assignment\\\\Group-99-InVDO\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncap = cv2.VideoCapture(vdofile)\\n\\nwhile(cap.isOpened()):\\n    frameId = cap.get(1) #current frame number\\n    ret, frame = cap.read()\\n    count=count+1\\n               \\n    # If Video frame was not successfully read then break the loop\\n    if (ret != True):\\n        break\\nprint ('Read a new frame: ', ret) \\nprint ('No of frame =' , count)\\n\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cap = cv2.VideoCapture(vdofile)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    count=count+1\n",
    "               \n",
    "    # If Video frame was not successfully read then break the loop\n",
    "    if (ret != True):\n",
    "        break\n",
    "print ('Read a new frame: ', ret) \n",
    "print ('No of frame =' , count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print ('Read a new frame: ', ret) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport moviepy.editor as mp  #For Audio\\n#from moviepy.editor import VideoFileClip\\nmy_clip = mp.VideoFileClip(vdofile)\\nprint(\"Duration of video : \", my_clip.duration)\\nprint(\"FPS : \", my_clip.fps)  # Frame per second\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. use AudioSegment to extract audio\n",
    "'''\n",
    "import moviepy.editor as mp  #For Audio\n",
    "#from moviepy.editor import VideoFileClip\n",
    "my_clip = mp.VideoFileClip(vdofile)\n",
    "print(\"Duration of video : \", my_clip.duration)\n",
    "print(\"FPS : \", my_clip.fps)  # Frame per second\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmy_clip.reader.close()\\ndel my_clip.reader\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "my_clip.reader.close()\n",
    "del my_clip.reader\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basketball and SoccerPenalty event detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCAMZC321_Group99_EventDetection_BP_PreProcessing_Step-0 - Check file name nomenclature\n",
    "#### PCAMZC241_Group5_VIDEOANALYTICS_PreProcessing_Step-0 - Check file name nomenclature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This scripts does \n",
    "###### 1. This script helps in creating the main folder stucture to store the frame.\n",
    "###### 2. reads the videos and selects the frames to be stored \n",
    "###### 3. Prepares the main CSV file with references to all frames alongwith their classes\n",
    "\n",
    "### Root folder \n",
    "###C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO\n",
    "\n",
    "\n",
    "### Input files location\n",
    "#### VDO files\n",
    "##### 1. C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO\\Basketball\n",
    "##### 2. C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO\\SoccerPenalty\n",
    "\n",
    "#### Train and Test vdo file names list \n",
    "##### 1. C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO\\train_list.csv\n",
    "##### 2. C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO\\test_list.csv\n",
    "\n",
    "### Output files location \n",
    "##### 1. C:\\GG-16-03\\CAP4\\HumanActivityRecognition\\Dataset\\VDO\\VDOFrames --- all frames \n",
    "##### 2. C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO\\Final_frameFile.csv  --- all frames\n",
    "##### 3. C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO\\trainFrames.csv\n",
    "##### 4. C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO\\testFrames.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.3.4\n",
      "numpy: 1.19.5\n",
      "cv2: 4.5.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "import numpy as np\n",
    "import numpy\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "import cv2                                 # for capturing videos\n",
    "print('cv2: {}'.format(cv2.__version__))\n",
    "\n",
    "import os, os.path\n",
    "from pathlib import Path\n",
    "import math   # for mathematical operations\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All VDOs stored in three folders - Basketball  and SoccerPenalty under root foler VDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\n"
     ]
    }
   ],
   "source": [
    "Drive = \"C:\"\n",
    "\n",
    "\n",
    "# Step-1-Process -  Extracting image frame from VDO \n",
    "\n",
    "## Define root folder\n",
    "root_folder = Drive+\"/1-GG/CAP4/EventDetection/1-ExampleSetting\"\n",
    "print(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root_folder where all inputs VDO are kept\n",
    "#root_folder = StepARootFolder\n",
    "#print(root_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - How to create folders using os library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\VDOFrames\n",
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\OutputFiles\n"
     ]
    }
   ],
   "source": [
    "FramesVdo  = root_folder+\"\\\\VDOFrames\"\n",
    "OutputFiles  = root_folder+\"\\OutputFiles\"\n",
    "\n",
    "\n",
    "if not os.path.exists(FramesVdo):\n",
    "   os.makedirs(FramesVdo) \n",
    "   \n",
    "if not os.path.exists(OutputFiles):\n",
    "   os.makedirs(OutputFiles) \n",
    "\n",
    "print(FramesVdo)\n",
    "print(OutputFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - How to read folders under root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AllFrames', 'Basketball', 'Client file', 'OutputFiles', 'SoccerPenalty', 'VDOFrames']\n"
     ]
    }
   ],
   "source": [
    "sub_folders = [name for name in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, name))]\n",
    "\n",
    "print(sub_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllFrames\n",
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\AllFrames\n",
      "Basketball\n",
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\Basketball\n",
      "Client file\n",
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\Client file\n",
      "SoccerPenalty\n",
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\SoccerPenalty\n"
     ]
    }
   ],
   "source": [
    "for child in os.listdir(root_folder):\n",
    "    if child == \"VDOFrames\":\n",
    "        continue\n",
    "    if child == \"OutputFiles\":\n",
    "        continue\n",
    "        \n",
    "    print(child)\n",
    "   \n",
    "    baseimagefolders = os.path.join(root_folder, child)\n",
    "    if os.path.isdir(baseimagefolders):\n",
    "        print(baseimagefolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\SoccerPenalty\n"
     ]
    }
   ],
   "source": [
    "print(baseimagefolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".avi\n"
     ]
    }
   ],
   "source": [
    "file = \"C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\SoccerPenalty/v_SoccerPenalty_g01_c01.avi\"\n",
    "extension = os.path.splitext(file)[1]\n",
    "print(extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_SoccerPenalty_g01_c01\n"
     ]
    }
   ],
   "source": [
    "temp = Path(file).stem # Find file name without extension\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\SoccerPenalty/v_SoccerPenalty_g01_c01.avi\n",
    "\n",
    "#  valid extensions of base image\n",
    "image_path_list = []\n",
    "\n",
    "valid_vdo_extensions = [\".mp4\" , \".avi\"] #specify vald extensions here\n",
    "valid_vdo_extensions = [item.lower() for item in valid_vdo_extensions]\n",
    "     \n",
    "#create a list all files in directory and\n",
    "#append files with a vaild extention to image_path_list\n",
    "for file in os.listdir(baseimagefolders):  ### extract each vdo from a given folder\n",
    "    #print(file)\n",
    "    extension = os.path.splitext(file)[1] ### How to extract only extension of a vdo file\n",
    "    if extension.lower() not in valid_vdo_extensions:\n",
    "        continue\n",
    "            \n",
    "    # image_path_list contains list of all vdo files with full path bame of a given vdo folder\n",
    "    image_path_list.append(os.path.join(baseimagefolders, file))\n",
    "    image_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end of Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main script - OpenCV comes with many powerful video editing functions. \n",
    "#### Techniques such as image scanning, face recognition can be accomplished using OpenCV.\n",
    "\n",
    "##### 1. Take a video as input and break the video into frame by frame and save those frame in a folder \"VDOFrames\" \n",
    "##### 2. \"vdo_Framing_Process\" function does this splitting indo frames\n",
    "##### 3. also write a csv (\"Final_frameFile.csv\") have 3 columns like \"FrameFilename\" , \"FullPathName\" and \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.3.4\n",
      "numpy: 1.19.5\n",
      "cv2: 4.5.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "import numpy as np\n",
    "import numpy\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "import cv2                                 # for capturing videos\n",
    "print('cv2: {}'.format(cv2.__version__))\n",
    "\n",
    "import os, os.path\n",
    "from pathlib import Path\n",
    "import math   # for mathematical operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\n"
     ]
    }
   ],
   "source": [
    "Drive = \"C:\"\n",
    "\n",
    "\n",
    "# Step-1-Process -  Extracting image frame from VDO \n",
    "\n",
    "## Define root folder\n",
    "root_folder = Drive+\"/1-GG/CAP4/EventDetection/1-ExampleSetting\"\n",
    "print(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "##### 1. Reading in the video frame-by-frame.\n",
    "##### 2. Within a second, a human body does not perform very significant movement. This implies that most of the frames (per second) in our video will be redundant. Therefore, only a subset of all the frames in a video needs to be extracted. This will also reduce the size of the input data which will in turn help the model train faster and can also prevent over-fitting.\n",
    "\n",
    "### Different strategies can be used for frame extraction as follows\n",
    "\n",
    "##### Extracting a fixed number of frames from the total frames in the video – say only the first 200 frames (i.e., first 8 seconds of the video).\n",
    "\n",
    "##### Extracting a fixed number of frames each second from the video – say we need only 5 frames per second from a video whose duration is of 10 seconds. This would return a total of 50 frames from the video. This approach is better in the sense that we are extracting the frames sparsely and uniformly from the entire video.\n",
    "\n",
    "##### Each frame needs to have the same spatial dimensions (height and width). Hence each frame in a video will have to be resized to the required size.\n",
    "\n",
    "##### The frames can be converted to grayscale.(not done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "def variance_of_laplacian(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def blurimagedetection():\n",
    "    paths=glob.glob(\"C:/1-GG/CAP4/EventDetection/Dataset/VDO1/VDOFrames/*.jpg\")\n",
    "    print(len(paths))\n",
    "\n",
    "    thvalue = 300\n",
    "    #imagePath = \"C:\\1-GG\\CAP4\\EventDetection\\Dataset\\VDO1\\VDOFrames\"\n",
    "    for image in paths:\n",
    "        image = cv2.imread(image)\n",
    "        print(image)\n",
    "    # Convert to grey scale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fm = variance_of_laplacian(gray)\n",
    "    text = \"Not Blurry\"\n",
    "    if fm < thvalue:\n",
    "        text = \"Blurry\"\t\n",
    "        print('Blurry')\n",
    "   # write to blurimage folder\n",
    "    if fm > thvalue:\n",
    "        text = \"Not Blurry\"\t\n",
    "        print('Not Blurry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check image pairs with similarity larget than threshold.\n",
    "# You can lower threshold to find more duplicates (and more false positives).\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "def duplicateImage():\n",
    "    hashes=duplicateHashing()\n",
    "    hashes = torch.Tensor(np.array(hashes).astype(int)).cuda()\n",
    "    # calc similarity scores\n",
    "    sims = np.array([(hashes[i] == hashes).sum(dim=1).cpu().numpy()/256 for i in range(hashes.shape[0])])\n",
    "    threshold = 0.96\n",
    "    duplicates = np.where(sims > threshold)\n",
    "    pairs = {}\n",
    "    for i,j in zip(*duplicates):\n",
    "        if i == j:\n",
    "            continue\n",
    "            path1 = paths[i]\n",
    "            path2 = paths[j]\n",
    "            print(path1)\n",
    "            print(path2)\n",
    "            image1 = cv2.imread(path1)\n",
    "            image2 = cv2.imread(path2)\n",
    "            if image1.shape[0] > image1.shape[1] / 2:\n",
    "                fig,ax = plt.subplots(figsize=(20,20), ncols=2)\n",
    "            elif image1.shape[1] > image1.shape[0] / 2:\n",
    "                    fig,ax = plt.subplots(figsize=(20,20), nrows=2)\n",
    "            else:\n",
    "                        fig,ax = plt.subplots(figsize=(20,30), nrows=2)\n",
    "                        ax[0].imshow(image1)\n",
    "                        ax[1].imshow(image2)\n",
    "                        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vdo_Framing_Process(child, imageDir,OutimageDir):\n",
    "#------------------\n",
    "    image_height, image_width = 64, 64\n",
    "\n",
    "    # Following 3 variables - for final csv \n",
    "    frame_filename = []\n",
    "    frame_image    = []\n",
    "    frame_class    = []\n",
    "    \n",
    "    \n",
    "    suffix = '.jpg'   # Extension of image file name \n",
    "    seq = 0\n",
    "    #  valid extensions of base image\n",
    "    image_path_list = []\n",
    "    valid_vdo_extensions = [\".mp4\" , \".avi\"] #specify vald extensions here\n",
    "    valid_vdo_extensions = [item.lower() for item in valid_vdo_extensions]\n",
    "     \n",
    "    #create a list all files in directory and\n",
    "    #append files with a vaild extention to image_path_list\n",
    "    for file in os.listdir(imageDir):  ### extract each vdo from a given folder\n",
    "        #print(file)\n",
    "        extension = os.path.splitext(file)[1] ### How to extract only extension of a vdo file\n",
    "        if extension.lower() not in valid_vdo_extensions:\n",
    "            continue\n",
    "        # image_path_list contains list of all vdo files with full path bame of a given vdo folder\n",
    "        image_path_list.append(os.path.join(imageDir, file))\n",
    "    #print(image_path_list)\n",
    "    \n",
    "    #loop through image_path_list to open each vdo - Read each vdo in a loop \n",
    "    for vdoFile in image_path_list:\n",
    "            count = 0\n",
    "            #print(vdoFile)\n",
    "            \n",
    "            cap = cv2.VideoCapture(vdoFile)   # capturing the video from the given path\n",
    "            ## vdoFile looks like \"C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/AllVdo/v_Basketball_g08_c01.avi\"\n",
    "            \n",
    "            frameRate = cap.get(5) #frame rate\n",
    "            x=1\n",
    "            while(cap.isOpened()):\n",
    "                frameId = cap.get(1) #current frame number\n",
    "                ret, frame = cap.read()\n",
    "                \n",
    "                # If Video frame was not successfully read then break the loop\n",
    "                if (ret != True):\n",
    "                    break\n",
    "                    \n",
    "                # Resize the Frame to fixed Dimensions\n",
    "                resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "    \n",
    "                #print(\"we are here\")\n",
    "                if (frameId % math.floor(frameRate) == 0):\n",
    "                    # storing the frames in a train frame folder \n",
    "                    temp = Path(vdoFile).stem # Find file name without extension\n",
    "                    \n",
    "                    # temp = os.path.splitext(vdoFile)[0]  ## Find file name without extension\n",
    "                    #print(temp)\n",
    "                    filename =\"/\"+ temp+\"_frame%d.jpg\" % count;count+=1\n",
    "                    Outimage = os.path.join(OutimageDir+filename)\n",
    "                    #print(Outimage)\n",
    "                    cv2.imwrite(Outimage, resized_frame)   # save frame as JPEG file\n",
    "                    \n",
    "                    FIlenameOnly = os.path.basename(vdoFile)\n",
    "                    \n",
    "                    ## storing the images and their class in a dataframe\n",
    "                    frame_filename.append(FIlenameOnly)  # Only filename\n",
    "                    frame_image.append(Outimage)         # File Name with complete path\n",
    "                    # creating the class of image        # Class i.e. Basketball , CricketBowling etc\n",
    "                    frame_class.append(child)\n",
    "            cap.release()\n",
    "\n",
    "\n",
    "    # storing the images and their class in a dataframe\n",
    "    train_data = pd.DataFrame()\n",
    "    train_data['FrameFilename'] = frame_filename\n",
    "    train_data['FullPathName'] = frame_image\n",
    "    train_data['class'] = frame_class\n",
    "    \n",
    "    # converting the dataframe into csv file \n",
    "    #train_data.to_csv('C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO/train_new.csv',header=True, index=False)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#pip install imagehash\n",
    "import imagehash\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "def duplicateHashing():\n",
    "    paths=glob.glob(\"C:/1-GG/CAP4/EventDetection/1-ExampleSetting/VDOFrames/*.jpg\")\n",
    "    funcs = [\n",
    "    imagehash.average_hash,\n",
    "    imagehash.phash,\n",
    "    imagehash.dhash,\n",
    "    imagehash.whash,\n",
    "    #lambda x: imagehash.whash(x, mode='db4'),\n",
    "    ]\n",
    "    hashes = []\n",
    "    for path in tqdm(paths, total=len(paths)):\n",
    "        image = cv2.imread(path)\n",
    "        image = Image.fromarray(image)\n",
    "        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n",
    "    return hashes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\VDOFrames\n",
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\OutputFiles\n"
     ]
    }
   ],
   "source": [
    "FramesVdo  = root_folder+\"\\\\VDOFrames\"\n",
    "OutputFiles  = root_folder+\"\\OutputFiles\"\n",
    "\n",
    "\n",
    "if not os.path.exists(FramesVdo):\n",
    "   os.makedirs(FramesVdo) \n",
    "   \n",
    "if not os.path.exists(OutputFiles):\n",
    "   os.makedirs(OutputFiles) \n",
    "\n",
    "print(FramesVdo)\n",
    "print(OutputFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script that call vdo_Framing_Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Folder : C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\AllFrames\n",
      "1\n",
      "(0, 3)\n",
      "Processing Folder : C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\Basketball\n",
      "2\n",
      "(705, 3)\n",
      "Processing Folder : C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\SoccerPenalty\n",
      "3\n",
      "(1292, 3)\n"
     ]
    }
   ],
   "source": [
    "# Main script that call vdo_Framing_Process \n",
    "\n",
    "kount = 0\n",
    "for child in os.listdir(root_folder):\n",
    "    if child == \"VDOFrames\":\n",
    "        continue\n",
    "    if child == \"OutputFiles\":\n",
    "        continue\n",
    "    if child == \"Client file\":\n",
    "        continue\n",
    "\n",
    "\n",
    "    kount = kount + 1\n",
    "    baseimagefolders = os.path.join(root_folder, child)\n",
    "    if os.path.isdir(baseimagefolders):\n",
    "        print(\"Processing Folder :\" , baseimagefolders)\n",
    "        outImage  = FramesVdo\n",
    "        \n",
    "        \n",
    "        ### Calling vdo_Framing_Process function\n",
    "        df = vdo_Framing_Process(child , baseimagefolders,outImage)\n",
    "        \n",
    "        print(kount)\n",
    "        if (kount == 1):  ### First iteration - copy function used to create df2 for csv\n",
    "            df2 = df.copy()\n",
    "        else:\n",
    "            df2 = pd.concat([df2 , df])  ### all other iteration concat function to append df2\n",
    "            #df2.append(df)\n",
    "        print(df2.shape)\n",
    "# converting the dataframe into csv file\n",
    "#blurimagedetection()\n",
    "#duplicateImage()\n",
    "#df2.to_csv('C:/GG-16-03/CAP4/HumanActivityRecognition/Dataset/VDO/Final_2vdoframeFile.csv',header=True, index=False)\n",
    "df2.to_csv(OutputFiles+'/Final_2vdoframeFile.csv',header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test (apply) vdo files list given \n",
    "#### use following files for train and apply dataset \n",
    "\n",
    "######  2, 'C:\\1-GG\\CAP4\\EventDetection\\1-ExampleSetting/test_BSvdo_list.csv\n",
    "\n",
    "##### Need to split train and apply set from Final_frameFile.csv using above files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define folder\n",
    "Drive = \"C:\"\n",
    "OutputFiles = Drive+\"/1-GG/CAP4/EventDetection/1-ExampleSetting/OutputFiles\"\n",
    "Final_frameFile  = pd.read_csv(OutputFiles+\"/Final_2vdoframeFile.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FrameFilename</th>\n",
       "      <th>FullPathName</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FrameFilename  \\\n",
       "0  v_Basketball_g01_c01.avi   \n",
       "1  v_Basketball_g01_c01.avi   \n",
       "2  v_Basketball_g01_c01.avi   \n",
       "3  v_Basketball_g01_c01.avi   \n",
       "4  v_Basketball_g01_c01.avi   \n",
       "\n",
       "                                        FullPathName       class  \n",
       "0  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  \n",
       "1  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  \n",
       "2  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  \n",
       "3  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  \n",
       "4  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_frameFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting\n"
     ]
    }
   ],
   "source": [
    "print(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1292, 3)\n",
      "(76, 3)\n"
     ]
    }
   ],
   "source": [
    "testSet  = pd.read_csv(root_folder+\"/Client file\"+\"/test_BSvdo_list.csv\")\n",
    "\n",
    "print(Final_frameFile.shape)\n",
    "\n",
    "print(testSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "      <th>VDOFileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basketball/v_Basketball_g01_c01.avi</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basketball/v_Basketball_g01_c02.avi</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>v_Basketball_g01_c02.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basketball/v_Basketball_g01_c03.avi</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>v_Basketball_g01_c03.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basketball/v_Basketball_g01_c04.avi</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>v_Basketball_g01_c04.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basketball/v_Basketball_g01_c05.avi</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>v_Basketball_g01_c05.avi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            video_name         tag               VDOFileName\n",
       "0  Basketball/v_Basketball_g01_c01.avi  Basketball  v_Basketball_g01_c01.avi\n",
       "1  Basketball/v_Basketball_g01_c02.avi  Basketball  v_Basketball_g01_c02.avi\n",
       "2  Basketball/v_Basketball_g01_c03.avi  Basketball  v_Basketball_g01_c03.avi\n",
       "3  Basketball/v_Basketball_g01_c04.avi  Basketball  v_Basketball_g01_c04.avi\n",
       "4  Basketball/v_Basketball_g01_c05.avi  Basketball  v_Basketball_g01_c05.avi"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract test set vdo files from Final_frameFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetVDOlist = testSet[\"VDOFileName\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v_Basketball_g01_c01.avi',\n",
       " 'v_Basketball_g01_c02.avi',\n",
       " 'v_Basketball_g01_c03.avi',\n",
       " 'v_Basketball_g01_c04.avi',\n",
       " 'v_Basketball_g01_c05.avi',\n",
       " 'v_Basketball_g01_c06.avi',\n",
       " 'v_Basketball_g01_c07.avi',\n",
       " 'v_Basketball_g02_c01.avi',\n",
       " 'v_Basketball_g02_c02.avi',\n",
       " 'v_Basketball_g02_c03.avi',\n",
       " 'v_Basketball_g02_c04.avi',\n",
       " 'v_Basketball_g02_c05.avi',\n",
       " 'v_Basketball_g02_c06.avi',\n",
       " 'v_Basketball_g03_c01.avi',\n",
       " 'v_Basketball_g03_c02.avi',\n",
       " 'v_Basketball_g03_c03.avi',\n",
       " 'v_Basketball_g03_c04.avi',\n",
       " 'v_Basketball_g03_c05.avi',\n",
       " 'v_Basketball_g03_c06.avi',\n",
       " 'v_Basketball_g04_c01.avi',\n",
       " 'v_Basketball_g04_c02.avi',\n",
       " 'v_Basketball_g04_c03.avi',\n",
       " 'v_Basketball_g04_c04.avi',\n",
       " 'v_Basketball_g05_c01.avi',\n",
       " 'v_Basketball_g05_c02.avi',\n",
       " 'v_Basketball_g05_c03.avi',\n",
       " 'v_Basketball_g05_c04.avi',\n",
       " 'v_Basketball_g06_c01.avi',\n",
       " 'v_Basketball_g06_c02.avi',\n",
       " 'v_Basketball_g06_c03.avi',\n",
       " 'v_Basketball_g06_c04.avi',\n",
       " 'v_Basketball_g07_c01.avi',\n",
       " 'v_Basketball_g07_c02.avi',\n",
       " 'v_Basketball_g07_c03.avi',\n",
       " 'v_Basketball_g07_c04.avi',\n",
       " 'v_SoccerPenalty_g01_c01.avi',\n",
       " 'v_SoccerPenalty_g01_c02.avi',\n",
       " 'v_SoccerPenalty_g01_c03.avi',\n",
       " 'v_SoccerPenalty_g01_c04.avi',\n",
       " 'v_SoccerPenalty_g01_c05.avi',\n",
       " 'v_SoccerPenalty_g01_c06.avi',\n",
       " 'v_SoccerPenalty_g02_c01.avi',\n",
       " 'v_SoccerPenalty_g02_c02.avi',\n",
       " 'v_SoccerPenalty_g02_c03.avi',\n",
       " 'v_SoccerPenalty_g02_c04.avi',\n",
       " 'v_SoccerPenalty_g02_c05.avi',\n",
       " 'v_SoccerPenalty_g03_c01.avi',\n",
       " 'v_SoccerPenalty_g03_c02.avi',\n",
       " 'v_SoccerPenalty_g03_c03.avi',\n",
       " 'v_SoccerPenalty_g03_c04.avi',\n",
       " 'v_SoccerPenalty_g03_c05.avi',\n",
       " 'v_SoccerPenalty_g04_c01.avi',\n",
       " 'v_SoccerPenalty_g04_c02.avi',\n",
       " 'v_SoccerPenalty_g04_c03.avi',\n",
       " 'v_SoccerPenalty_g04_c04.avi',\n",
       " 'v_SoccerPenalty_g04_c05.avi',\n",
       " 'v_SoccerPenalty_g05_c01.avi',\n",
       " 'v_SoccerPenalty_g05_c02.avi',\n",
       " 'v_SoccerPenalty_g05_c03.avi',\n",
       " 'v_SoccerPenalty_g05_c04.avi',\n",
       " 'v_SoccerPenalty_g05_c05.avi',\n",
       " 'v_SoccerPenalty_g05_c06.avi',\n",
       " 'v_SoccerPenalty_g05_c07.avi',\n",
       " 'v_SoccerPenalty_g06_c01.avi',\n",
       " 'v_SoccerPenalty_g06_c02.avi',\n",
       " 'v_SoccerPenalty_g06_c03.avi',\n",
       " 'v_SoccerPenalty_g06_c04.avi',\n",
       " 'v_SoccerPenalty_g06_c05.avi',\n",
       " 'v_SoccerPenalty_g06_c06.avi',\n",
       " 'v_SoccerPenalty_g06_c07.avi',\n",
       " 'v_SoccerPenalty_g07_c01.avi',\n",
       " 'v_SoccerPenalty_g07_c02.avi',\n",
       " 'v_SoccerPenalty_g07_c03.avi',\n",
       " 'v_SoccerPenalty_g07_c04.avi',\n",
       " 'v_SoccerPenalty_g07_c05.avi',\n",
       " 'v_SoccerPenalty_g07_c06.avi']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSetVDOlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FrameFilename', 'FullPathName', 'class'], dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_frameFile.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFrames = Final_frameFile[Final_frameFile['FrameFilename'].isin(testSetVDOlist)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFrames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FrameFilename</th>\n",
       "      <th>FullPathName</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v_Basketball_g01_c01.avi</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              FrameFilename  \\\n",
       "0  v_Basketball_g01_c01.avi   \n",
       "1  v_Basketball_g01_c01.avi   \n",
       "2  v_Basketball_g01_c01.avi   \n",
       "3  v_Basketball_g01_c01.avi   \n",
       "4  v_Basketball_g01_c01.avi   \n",
       "\n",
       "                                        FullPathName       class  \n",
       "0  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  \n",
       "1  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  \n",
       "2  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  \n",
       "3  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  \n",
       "4  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...  Basketball  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFrames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract test set vdo files from Final_frameFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For train frame - all rows except (~) the test vdo list\n",
    "trainFrames = Final_frameFile[~Final_frameFile['FrameFilename'].isin(testSetVDOlist)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(973, 3)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFrames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Common Rows between two Dataframe - trainFrames , testFrames - There should not be common row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FrameFilename</th>\n",
       "      <th>FullPathName</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [FrameFilename, FullPathName, class]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find Common Rows between two Dataframe - trainFrames , testFrames - There should not be common row\n",
    "\n",
    "dfcommon = trainFrames.merge(testFrames, how = 'inner' ,indicator=False)\n",
    "dfcommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store Train and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFrames.to_csv(OutputFiles+'/trainFrames.csv',header=True, index=False)\n",
    "testFrames.to_csv(OutputFiles+'/testFrames.csv',header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
