{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model on vdo having no class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaghos\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\jaghos\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\jaghos\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy import stats as s\n",
    "\n",
    "from moviepy.editor import *   ###VideoFileClip\n",
    "\n",
    "\n",
    "## pafy, youtube-dl and moviepy packages to be installed\n",
    "##pip install pafy youtube-dl moviepy\n",
    "\n",
    "## Install open cv - make sure numpy already installed\n",
    "#pip install opencv-python\n",
    "#import pafy\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FrameFilename</th>\n",
       "      <th>FullPathName</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MoreBasketBallVdo.mp4</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MoreBasketBallVdo.mp4</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MoreBasketBallVdo.mp4</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MoreBasketBallVdo.mp4</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoreBasketBallVdo.mp4</td>\n",
       "      <td>C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FrameFilename                                       FullPathName  \\\n",
       "0  MoreBasketBallVdo.mp4  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...   \n",
       "1  MoreBasketBallVdo.mp4  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...   \n",
       "2  MoreBasketBallVdo.mp4  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...   \n",
       "3  MoreBasketBallVdo.mp4  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...   \n",
       "4  MoreBasketBallVdo.mp4  C:/1-GG/CAP4/EventDetection/1-ExampleSetting\\V...   \n",
       "\n",
       "        class  \n",
       "0  Basketball  \n",
       "1  Basketball  \n",
       "2  Basketball  \n",
       "3  Basketball  \n",
       "4  Basketball  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Drive = \"C:\"\n",
    "## Define root folder\n",
    "RootFolder = Drive+\"/1-GG/CAP4/EventDetection/1-ExampleSetting/OutputFiles\"\n",
    "\n",
    "trainFrames  = pd.read_csv(RootFolder+\"/trainFrames.csv\")\n",
    "\n",
    "trainFrames.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basketball', 'SoccerPenalty']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values of 'class' column - How many distinct classes\n",
    "model_class = trainFrames['class'].unique().tolist()\n",
    "print(model_class)\n",
    "model_output_size = len(model_class)\n",
    "print(model_output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VGG-16 pre-trained model will be used\n",
    "# creating the base model of pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/1-GG/CAP4/EventDetection/1-ExampleSetting/combined_video-2vdo.mp4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the YouTube Video's path you just downloaded\n",
    "output_directory = 'C:/1-GG/CAP4/EventDetection/1-ExampleSetting'   # where is my VDO file ?\n",
    "\n",
    "##video_title = \"combined_3video\"\n",
    "video_title = \"combined_video-2vdo\"\n",
    "\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "input_video_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting sthe Window Size which will be used by the Rolling Average Proces\n",
    "window_size = 1\n",
    "\n",
    "# Constructing The Output YouTube Video Path\n",
    "#output_video_file_path = f'{output_directory}/{video_title} -Output-WSize {window_size}.mp4'\n",
    "\n",
    "#print(output_video_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2673, 7, 7, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    %%time\n",
    "    image_height  = 224\n",
    "    image_width   = 224\n",
    "    \n",
    "    # Initialize a Deque Object with a fixed size which will be used to implement moving/rolling average functionality.\n",
    "    #predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    "\n",
    "    # Reading the Video File using the VideoCapture Object\n",
    "    video_reader = cv2.VideoCapture(input_video_file_path)\n",
    "\n",
    "    # Getting the width and height of the video \n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Writing the Overlayed Video Files Using the VideoWriter Object\n",
    "    #video_writer = cv2.VideoWriter(output_video_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), 24, (original_video_width, original_video_height))\n",
    "\n",
    "\n",
    "    prediction_images = []\n",
    "    while True: \n",
    "\n",
    "        # Reading The Frame\n",
    "        status, frame = video_reader.read() \n",
    "\n",
    "        if not status:\n",
    "            break\n",
    "\n",
    "        #print(\"we are here\")\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        resized_frame = image.img_to_array(resized_frame)\n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        \n",
    "        \n",
    "        # converting the list to numpy array\n",
    "        # appending the image to the image list\n",
    "        prediction_images.append(normalized_frame)\n",
    "    # converting the list to numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "        \n",
    "    # shape of the array\n",
    "    prediction_images.shape\n",
    "    # extracting features for validation frames\n",
    "    prediction_images = base_model.predict(prediction_images)\n",
    "    prediction_images.shape\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converting features in one dimensional array\n",
    "prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2673, 25088)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max = prediction_images.max()\n",
    "prediction_images = prediction_images/max\n",
    "prediction_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Pre Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load  model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/1-GG/CAP4/EventDetection/1-ExampleSetting/OutputFiles'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RootFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'video combined_video-2vdo model_jj.h5'\n",
    "\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model(RootFolder+'/'+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-7056c4edee29>:3: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predict = []        \n",
    "# predict_classes() function model in order to predict the class values for each instance in the array.\n",
    "prediction = model.predict_classes(prediction_images)\n",
    "# prediction is an arrary containing frame by frame class prediction - here either Basketball', 'SoccerPenalty'\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle is the standard way of serializing objects in Python.\n",
    "\n",
    "#### Use the pickle operation to serialize  machine learning algorithms and save the serialized format to a file.\n",
    "\n",
    "#### Later we can load this file to deserialize your model and use it to make new predictions.\n",
    "\n",
    "#### Serialization is the process of converting an object into a stream of bytes to store the object or transmit it to memory, or a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save prediction array using pickle dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('combinedPrediction_j', 'wb') as fp:\n",
    "    pickle.dump(prediction, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read it back:\n",
    "with open ('combinedPrediction_j', 'rb') as fp:\n",
    "    prediction = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function To Predict on Live Videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/1-GG/CAP4/EventDetection/1-ExampleSetting/combined_video-2vdo -2vdoOutput.mp4\n"
     ]
    }
   ],
   "source": [
    "output_directory = 'C:/1-GG/CAP4/EventDetection/1-ExampleSetting'\n",
    "\n",
    "\n",
    "\n",
    "video_title = \"combined_video-2vdo\"\n",
    "\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "input_video_file_path\n",
    "\n",
    "\n",
    "# Constructing The Output YouTube Video Path\n",
    "output_video_file_path = f'{output_directory}/{video_title} -2vdoOutput.mp4'\n",
    "\n",
    "print(output_video_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Basketball', 'SoccerPenalty']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SoccerPenalty'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = len(prediction)\n",
    "print(x)\n",
    "# Accessing The Class Name using predicted label.\n",
    "predicted_class_name = model_class[prediction[2]]\n",
    "predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/1-GG/CAP4/EventDetection/1-ExampleSetting/combined_video-2vdo.mp4'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_video_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/1-GG/CAP4/EventDetection/1-ExampleSetting/combined_video-2vdo -2vdoOutput.mp4'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_video_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_live_video(video_file_path, output_file_path):\n",
    "\n",
    "    # Initialize a Deque Object with a fixed size which will be used to implement moving/rolling average functionality.\n",
    "    #predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    "    \n",
    "    frame_no = -1\n",
    "\n",
    "    # Reading the Video File using the VideoCapture Object\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    # Getting the width and height of the video \n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Writing the Overlayed Video Files Using the VideoWriter Object\n",
    "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), 24, (original_video_width, original_video_height))\n",
    "\n",
    "    while True: \n",
    "\n",
    "        # Reading The Frame\n",
    "        status, frame = video_reader.read() \n",
    "\n",
    "        if not status:\n",
    "            break\n",
    "\n",
    "        frame_no = frame_no+1\n",
    "        \n",
    "        # some frames with black - skip those\n",
    "        ## images in openCV (or in your case frames) are represented as a numpy array, \n",
    "        ## they can be averaged for low values (which represent black frames).\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  ## Convert to grey image (black and white)\n",
    "        if np.average(gray) < 20:  ## if it dark screen , skip \n",
    "        # skips an iteration, so the frame isn't saved\n",
    "          continue\n",
    "        \n",
    "\n",
    "           \n",
    "        # Accessing The Class Name using prediction list.\n",
    "        predicted_class_name = model_class[prediction[frame_no]]\n",
    "        #print(predicted_class_name)\n",
    "        \n",
    "        # Overlaying Class Name Text Ontop of the Frame\n",
    "        cv2.putText(frame, predicted_class_name, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        #cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        #cv2.putText(frame, avg_prob, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        \n",
    "        #cv2.putText(frame, \n",
    "                    #avg_prob, \n",
    "                    #(10, 100),   # bottomLeftCornerOfText\n",
    "                    #cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    #1, \n",
    "                    #(0, 0, 255), \n",
    "                    #2)\n",
    "                       \n",
    "        # Writing The Frame\n",
    "        video_writer.write(frame)\n",
    "    \n",
    "    # Closing the VideoCapture and VideoWriter objects and releasing all resources held by them. \n",
    "    video_reader.release()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output video file created\n"
     ]
    }
   ],
   "source": [
    "# Calling the predict_on_live_video method to start the Prediction.\n",
    "predict_on_live_video(input_video_file_path, output_video_file_path)\n",
    "print(\"output video file created\")\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "#VideoFileClip(input_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
